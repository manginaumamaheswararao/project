{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b53uOWALhp1P"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit pyngrok seaborn scikit-learn openpyxl\n",
        "\n",
        "# Import necessary modules\n",
        "import subprocess\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "# Create the Streamlit script\n",
        "streamlit_script = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, r2_score, precision_recall_curve, average_precision_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# Set the project title\n",
        "st.set_page_config(page_title=\"Automated ML Pipeline\")\n",
        "\n",
        "# Initialize session state to store results\n",
        "if 'model_accuracies' not in st.session_state:\n",
        "    st.session_state.model_accuracies = {}\n",
        "if 'pipeline_times' not in st.session_state:\n",
        "    st.session_state.pipeline_times = {}\n",
        "if 'results' not in st.session_state:\n",
        "    st.session_state.results = {}\n",
        "\n",
        "# Function to create preprocessing pipeline\n",
        "def create_preprocessing_pipeline(data, numeric_strategy, fill_value=None):\n",
        "    # Automatically detect numerical and categorical columns\n",
        "    numeric_features = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    categorical_features = data.select_dtypes(include=['object', 'bool', 'category']).columns.tolist()\n",
        "\n",
        "    # Create transformers for preprocessing\n",
        "    if numeric_strategy == 'custom':\n",
        "        # Ensure fill_value is appropriate for the column's datatype\n",
        "        numeric_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='constant', fill_value=fill_value)),\n",
        "            ('scaler', StandardScaler())\n",
        "        ])\n",
        "    else:\n",
        "        numeric_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy=numeric_strategy)),\n",
        "            ('scaler', StandardScaler())\n",
        "        ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features)\n",
        "        ])\n",
        "\n",
        "    return preprocessor, numeric_features + categorical_features\n",
        "\n",
        "# Function to encode categorical features\n",
        "def encode_categorical(data):\n",
        "    label_encoders = {}\n",
        "    categorical_features = data.select_dtypes(include=['object', 'bool', 'category']).columns.tolist()\n",
        "    for col in categorical_features:\n",
        "        le = LabelEncoder()\n",
        "        data[col] = le.fit_transform(data[col])\n",
        "        label_encoders[col] = le\n",
        "    return data, label_encoders\n",
        "\n",
        "# Streamlit app\n",
        "st.title(\"Automated Data Preparation and Machine Learning Pipeline\")\n",
        "\n",
        "# Upload datasets\n",
        "uploaded_files = st.file_uploader(\"Upload your CSV or Excel files\", type=[\"csv\", \"xlsx\"], accept_multiple_files=True)\n",
        "\n",
        "if uploaded_files:\n",
        "    datasets = {}\n",
        "    for uploaded_file in uploaded_files:\n",
        "        if uploaded_file.name.endswith('.csv'):\n",
        "            data = pd.read_csv(uploaded_file)\n",
        "        else:\n",
        "            data = pd.read_excel(uploaded_file)\n",
        "        datasets[uploaded_file.name] = data\n",
        "\n",
        "    for name, data in datasets.items():\n",
        "        st.write(f\"Uploaded Dataset - {name}:\", data.head())\n",
        "\n",
        "        # Show missing values\n",
        "        missing_values = data.isnull().sum()\n",
        "        if missing_values.sum() > 0:\n",
        "            st.write(f\"Missing Values in {name}:\", missing_values)\n",
        "        else:\n",
        "            st.success(f\"No missing values in {name}!\")\n",
        "\n",
        "        if missing_values.sum() > 0:\n",
        "            # Handle missing values\n",
        "            numeric_strategy = st.selectbox(f\"Select strategy for handling missing values in numerical columns for {name}\", [\"mean\", \"median\", \"most_frequent\", \"custom\"], key=f\"strategy_{name}\")\n",
        "            fill_value = None\n",
        "            if numeric_strategy == 'custom':\n",
        "                min_val = float(data.select_dtypes(include=[np.number]).min().min())\n",
        "                max_val = float(data.select_dtypes(include=[np.number]).max().max())\n",
        "                fill_value = st.slider(f\"Select a value to fill missing values in {name}\", min_val, max_val, key=f\"fill_value_{name}\")\n",
        "\n",
        "        # Encode categorical columns to numerical\n",
        "        data_encoded, label_encoders = encode_categorical(data)\n",
        "        st.write(f\"Dataset after encoding categorical features for {name}:\", data_encoded.head())\n",
        "\n",
        "        # Choose target column\n",
        "        target_column = st.selectbox(f\"Select the target column for {name}\", data.columns, key=f\"target_{name}\")\n",
        "\n",
        "        if target_column:\n",
        "            y = data_encoded[target_column]\n",
        "            X = data_encoded.drop(target_column, axis=1)\n",
        "\n",
        "            if missing_values.sum() > 0:\n",
        "                preprocessor, feature_names = create_preprocessing_pipeline(X, numeric_strategy, fill_value)\n",
        "            else:\n",
        "                preprocessor, feature_names = create_preprocessing_pipeline(X, 'mean')  # Default to mean if no missing values\n",
        "            X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "            # Option to plot pair plots before and after transformation\n",
        "            if st.button(f\"Plot Pair Plots Before Transformation for {name}\"):\n",
        "                st.write(f\"Pair Plot Before Transformation for {name}:\")\n",
        "                sns.pairplot(data_encoded, diag_kind=None)\n",
        "                st.pyplot(plt.gcf())\n",
        "\n",
        "            if st.button(f\"Plot Pair Plots After Transformation for {name}\"):\n",
        "                st.write(f\"Pair Plot After Transformation for {name}:\")\n",
        "                transformed_data = pd.DataFrame(X_preprocessed, columns=feature_names)\n",
        "                transformed_data[target_column] = y.values\n",
        "                sns.pairplot(transformed_data, diag_kind=None)\n",
        "                st.pyplot(plt.gcf())\n",
        "\n",
        "            # Select task type\n",
        "            task_type = st.selectbox(f\"Select the task type for {name}\", [\"Classification\", \"Regression\"], key=f\"task_{name}\")\n",
        "\n",
        "            model = None\n",
        "\n",
        "            if task_type == \"Classification\":\n",
        "                model_name = st.selectbox(f\"Select the classification model for {name}\", [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Support Vector Machine\", \"K-Nearest Neighbors\", \"Naive Bayes\"], key=f\"class_model_{name}\")\n",
        "                if model_name == \"Logistic Regression\":\n",
        "                    model = OneVsRestClassifier(LogisticRegression(max_iter=1000, random_state=42))\n",
        "                elif model_name == \"Decision Tree\":\n",
        "                    model = DecisionTreeClassifier(random_state=42)\n",
        "                elif model_name == \"Random Forest\":\n",
        "                    model = RandomForestClassifier(random_state=42)\n",
        "                elif model_name == \"Support Vector Machine\":\n",
        "                    model = OneVsRestClassifier(SVC(probability=True, random_state=42))  # Enable probability estimates for PR curve\n",
        "                elif model_name == \"K-Nearest Neighbors\":\n",
        "                    model = KNeighborsClassifier()\n",
        "                elif model_name == \"Naive Bayes\":\n",
        "                    model = GaussianNB()\n",
        "            else:\n",
        "                model_name = st.selectbox(f\"Select the regression model for {name}\", [\"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"Support Vector Machine\", \"K-Nearest Neighbors\"], key=f\"reg_model_{name}\")\n",
        "                if model_name == \"Linear Regression\":\n",
        "                    model = LinearRegression()\n",
        "                elif model_name == \"Decision Tree\":\n",
        "                    model = DecisionTreeRegressor(random_state=42)\n",
        "                elif model_name == \"Random Forest\":\n",
        "                    model = RandomForestRegressor(random_state=42)\n",
        "                elif model_name == \"Support Vector Machine\":\n",
        "                    model = SVR()\n",
        "                elif model_name == \"K-Nearest Neighbors\":\n",
        "                    model = KNeighborsRegressor()\n",
        "\n",
        "            if st.button(f\"Run Task for {name}\"):\n",
        "                start_time = time.time()\n",
        "                # Split data into training and test sets\n",
        "                X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "                model.fit(X_train, y_train)\n",
        "\n",
        "                # Evaluate the model\n",
        "                y_pred = model.predict(X_test)\n",
        "                end_time = time.time()\n",
        "\n",
        "                if task_type == \"Classification\":\n",
        "                    accuracy = accuracy_score(y_test, y_pred)\n",
        "                    st.write(f\"Model accuracy for {name}: {accuracy}\")\n",
        "                    st.session_state.model_accuracies[name] = accuracy\n",
        "                    # Display confusion matrix\n",
        "                    cm = confusion_matrix(y_test, y_pred)\n",
        "                    st.write(f\"Confusion Matrix for {name}:\")\n",
        "                    fig, ax = plt.subplots(figsize=(10, 7))\n",
        "                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "                    st.pyplot(fig)\n",
        "\n",
        "                    # Plot Precision-Recall Curve for multiclass\n",
        "                    y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
        "                    y_prob = model.predict_proba(X_test)\n",
        "                    precision = dict()\n",
        "                    recall = dict()\n",
        "                    average_precision = dict()\n",
        "                    for i in range(y_test_bin.shape[1]):\n",
        "                        precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_prob[:, i])\n",
        "                        average_precision[i] = average_precision_score(y_test_bin[:, i], y_prob[:, i])\n",
        "\n",
        "                    # Plot all PR curves\n",
        "                    fig, ax = plt.subplots(figsize=(10, 7))\n",
        "                    for i, color in zip(range(y_test_bin.shape[1]), plt.cm.rainbow(np.linspace(0, 1, y_test_bin.shape[1]))):\n",
        "                        ax.plot(recall[i], precision[i], color=color, lw=2, label=f'PR curve (AP = {average_precision[i]:0.2f}) for class {i}')\n",
        "                    ax.set_xlabel('Recall')\n",
        "                    ax.set_ylabel('Precision')\n",
        "                    ax.set_title('Precision-Recall Curve')\n",
        "                    ax.legend(loc=\"lower left\")\n",
        "                    st.pyplot(fig)\n",
        "\n",
        "                else:\n",
        "                    mse = mean_squared_error(y_test, y_pred)\n",
        "                    r2 = r2_score(y_test, y_pred)\n",
        "                    st.write(f\"Mean Squared Error for {name}: {mse}\")\n",
        "                    st.write(f\"R^2 Score for {name}: {r2}\")\n",
        "\n",
        "                    # Line plot of predicted vs actual values\n",
        "                    fig, ax = plt.subplots(figsize=(10, 7))\n",
        "                    ax.plot(y_test.values, label='Actual')\n",
        "                    ax.plot(y_pred, label='Predicted', linestyle='--')\n",
        "                    ax.set_title('Actual vs Predicted Values')\n",
        "                    ax.legend()\n",
        "                    st.pyplot(fig)\n",
        "\n",
        "                st.session_state.pipeline_times[name] = end_time - start_time\n",
        "                st.session_state.results[name] = {\n",
        "                    'accuracy': accuracy if task_type == \"Classification\" else None,\n",
        "                    'mse': mse if task_type == \"Regression\" else None,\n",
        "                    'r2': r2 if task_type == \"Regression\" else None,\n",
        "                    'time': end_time - start_time\n",
        "                }\n",
        "\n",
        "    # Button to plot model accuracies and pipeline times\n",
        "    if st.button(\"Plot Model Accuracies and Pipeline Times\"):\n",
        "        # Plot model accuracies\n",
        "        if st.session_state.model_accuracies:\n",
        "            st.write(\"Model Accuracies Comparison\")\n",
        "            fig, ax = plt.subplots(figsize=(12, 8))\n",
        "            ax.bar(st.session_state.model_accuracies.keys(), st.session_state.model_accuracies.values())\n",
        "            ax.set_ylabel(\"Accuracy\")\n",
        "            ax.set_title(\"Model Accuracies for Different Datasets\")\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            st.pyplot(fig)\n",
        "\n",
        "        # Plot pipeline times\n",
        "        if st.session_state.pipeline_times:\n",
        "            st.write(\"Pipeline Processing Time Comparison\")\n",
        "            fig, ax = plt.subplots(figsize=(12, 8))\n",
        "            ax.bar(st.session_state.pipeline_times.keys(), st.session_state.pipeline_times.values())\n",
        "            ax.set_ylabel(\"Time (seconds)\")\n",
        "            ax.set_title(\"Pipeline Processing Time for Different Datasets\")\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            st.pyplot(fig)\n",
        "\n",
        "        # Combined plot for accuracy and time\n",
        "        if st.session_state.model_accuracies and st.session_state.pipeline_times:\n",
        "            st.write(\"Combined Comparison of Model Accuracies and Pipeline Processing Time\")\n",
        "            fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "            color = 'tab:blue'\n",
        "            ax1.set_xlabel('Dataset')\n",
        "            ax1.set_ylabel('Accuracy', color=color)\n",
        "            ax1.bar(st.session_state.model_accuracies.keys(), st.session_state.model_accuracies.values(), color=color, alpha=0.6, label='Accuracy')\n",
        "            ax1.tick_params(axis='y', labelcolor=color)\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "            ax2 = ax1.twinx()\n",
        "            color = 'tab:red'\n",
        "            ax2.set_ylabel('Time (seconds)', color=color)\n",
        "            ax2.plot(list(st.session_state.pipeline_times.keys()), list(st.session_state.pipeline_times.values()), color=color, marker='o', linestyle='-', label='Time')\n",
        "            ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "            fig.tight_layout()\n",
        "            fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
        "            st.pyplot(fig)\n",
        "\"\"\"\n",
        "\n",
        "# Save the Streamlit script to a file\n",
        "with open(\"streamlit_app.py\", \"w\") as f:\n",
        "    f.write(streamlit_script)\n",
        "\n",
        "# Function to run the Streamlit app\n",
        "def run_streamlit_app():\n",
        "    # Stop any existing Streamlit processes\n",
        "    try:\n",
        "        result = subprocess.run([\"pgrep\", \"-f\", \"streamlit\"], capture_output=True, text=True)\n",
        "        pids = result.stdout.split()\n",
        "        for pid in pids:\n",
        "            subprocess.run([\"kill\", \"-9\", pid])\n",
        "    except Exception as e:\n",
        "        print(f\"Error stopping existing Streamlit processes: {e}\")\n",
        "\n",
        "    # Run the Streamlit app\n",
        "    streamlit_process = subprocess.Popen([\"streamlit\", \"run\", \"streamlit_app.py\"])\n",
        "\n",
        "    return streamlit_process\n",
        "\n",
        "# Run the Streamlit app\n",
        "run_streamlit_app()\n",
        "\n",
        "# Set up ngrok tunnel\n",
        "ngrok.set_auth_token(\"2hiaP2Ku5MWuGgnHbi8FK4XFlwD_5yEXv7TvcAKvKKgFoK6Xo\")\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is running at {public_url}\")"
      ]
    }
  ]
}